# HighLoad

The project was developed as part of the Technopark's high-load systems course.

---

### Тема проекта:

Социальная сеть - TikTok.

### Целевая аудитория сервиса:

- Российская аудитория ~ [23.1 млн](https://www.businessofapps.com/data/tik-tok-statistics/#5)

### MVP проекта:

1. Авторизация, регистрация, профиль пользователя;
2. Просмотр видео;
3. Поиск.

### Расчет нагрузки (Россия):

#### Исходные данные ([Источник](https://news.cpa.ru/tiktok-showed-audience-statistics/)):

- Среднее время, которое проводит пользователь в приложении за день: 45 мин;
- Среднее число заходов в приложение за день: 6-7;
- Максимальная длина ролика: 1 минута;
- Минимальная длина ролика: 15 секунд;
- Максимальный размер видео: 75Mb (android), 250Mb (ios);
- Число ежедневных просмотров видео: 666 млн;
- Число ежедневных загрузок видео: 666 тыс;
- Прирост Российской аудитории за 2020 год: [141%](https://www.businessofapps.com/data/tik-tok-statistics/#5)
- Среднее число [хэштегов в видео: 4](https://rusability.ru/articles/Heshtegi-dlya-Tik-Tok-kak-podobrat,-ispolzovat-i-prodvigatsya-bistree-konkurentov/5fd296ad2dda593c3483efc4);
- Используемые формат видео и кодек: [MP4, H.264](https://vtiktok.ru/harakteristiki-video-dlya-tik-tok/)
#### Расчеты:

- Среднее число просмотренных видео за день: 45 мин / 1.25 мин = 36 видео. Среднее время одного сеанса пользователя: 45 мин
/ 6 = 6.5 мин. За это время, учитывая среднее время ролика в 37 сек, можно успеть посмотреть 10 видео. При этом каждое
новое видео требует запроса не только к видеофайлу, но и запроса бизнес-логики, который позволит получить число лайков,
комментариев, подписчиков и прочие вспомогательные данные. Так как при загрузке контента сначала появляется информация о
видео, убеждаемся, что происходит как минимум два запроса.

`Значит, в среднем для одного пользователя осуществляется 36 / 60 = 0.6 rpm в течение 6.5 мин за видео-контентом`

Так как средний прирост пользователей за 2020 год составил 141%, будем считать, что пиковый онлайн составит 23 млн / 2 +
0.41*(16.4 млн) ~ 18.3 млн

`Тогда при одновременном просмотре видео выходит: 0.6 / 60 * 18.3 * 10 ^ 6 rps ~ 183 000 rps при пиковом онлайне`

- Средний объем трафика для одного
  пользователя: [16 Mb/min](https://www.quora.com/What-uses-more-data-watching-YouTube-videos-for-an-hour-or-TikTok-videos-for-an-hour)
- Средний объем выгружаемого на сервер видео-контента: (75+250)/2 = 162.5 Mb;
- Скорость выгрузки контента зависит от скорости интернет соединения (~15Mb/sec) и в среднем составляет: 11 сек; 
  
Будем считать, что информация, сопутствующая видео (число лайков, комментарии, подписки, картинки) занимает
15% от общего объема переданного контента, то есть 0.15 * 16 = 2.4 Mb / min
Отнесем эту работу с этой частью контента к бизнес-логике.

`Общий объем трафика за 1 секунду в пиковой нагрузке для:`

- Просмотра видео-контента : (13.6 Mb * 18.3 * 10 ^ 6) / 60  ~ **31.65 Tbit/s**
- Выгрузки на сервер видео-контента: (162.5 Mb * 18.3 * 10 ^ 3) / 60  ~ **0.38 Tbit/s** 
- Другие операции (бизнес-логика): (2.4 Mb * 18.3 * 10 ^ 6) / 60 ~ **5.58 Tbit/s**

`Результирующие порядки RPS по типам запросов при средней загруженности серверов`

    Запросы за видео: 666 * 10^6 / (24 * 3600) ~= 7700 RPS
    Запросы на загрузку видео: 666 * 10^5 / (24 * 3600) ~= 770 RPS
    Запросы бизнес-логики 2 * 666 * 10^6 / (24 * 3600) ~= 15400 RPS

### Логическая схема БД:

---
![Иллюстрация к проекту](https://raw.githubusercontent.com/H-b-IO-T-O-H/HighLoad/main/subd_sheme/subd_logic.png)

### Физическая схема БД:

Размер uuid - 16 bytes
Кодек H.204 для видео формата 1280x960 px обеспечивает сжатие почти в [75 раз](https://samara.spycams.ru/sovet/raschjot-arhiva-sistemy-videonabljudenija)
Будем считать, что в среднем коэффициент сжатия будет составлять 70.

    videos:
      video_id(16) + title(150) + author_name(24) + autor_id(16) + duration(4) + likes_cnt(8) + audio_file_title(50) + path_to_video_file(128) + file_prefix(16) = 412 bytes
      
    Количество загружаемых видео: 20 * 10^6 / month, на первый год потребуется 12 * 20 * 10^6 * 412 ~ 92.1 Gb для хранения в бд 
    и 12 * 20 * 10^6 * 162.5 / 70 ~  531.33 Tb в файловом хранилище
    
    users:
      user_id(16) + name(20) + username(24) + email(128) + phone(11) + password(128) + total_likes_cnt(8) + followers_cnt(8) + following_cnt(8) + recommendation_id(16) = 367 bytes
      Количество пользователей в России: 23.1 * 10^6, потребуется 23.1 * 10^6 * 367 ~ 7.9 Gb
    
    followers:
      follower_id(16) + user_id(16) + follower_name(24) = 56 bytes
      Будем считать только Российский сегмент без подписок на иностранных авторов: 
      потребуется 23.1 * 10^6 * 56 ~ 1.2 Gb
    
    hashtags:
      hashtag_id(16) + hashtag(100) + followers_cnt(8) + is_trend(1) ~ 125 bytes
      В среднем для видео генерируется 4 хэштега. Для Российского сегмента потребуется:
      12 * 20 * 4 * 10^6 * 125 ~ 111 Gb

    recommendations:
      Предположим, рекомендации пользователя определяются на основании 10 последних просмотренных видео и 5 наиболее популярных хэштегов.
      recommendation_id(16) + user_id(16) + favourites_videos_id(16 * 10) +  favourites_hashtags_id(16 * 5) + average_video_duration(4) = 356 bytes
      23.1 * 10^6 * 356 ~ 7.66 Gb

|Сущность|Объем памяти на год работы, Гб|
| -------------  | :-------------:  |
|Users|7.9|
|Recommendations|7.66|
|Videos|92.1 Гб / 531.33 Tб|
|Hashtags|111|
|Followers|1.2|

### Выбор СУБД

Данные пользователей, информацию о видео, подписках и рекоммендациях будут храниться в PostgreSQL, как в хорошо
зарекомендовавшей себя реляционной БД, котарая поддерживает все необходимые средства для ораганизации распределенных
систем. Данные о сессии будут храниться в Redis из-за его высокой скорости работы.

### Шардирование и репликация

- Видео будет распределено на нескольких файловых хранилищах (например HDD) на основании файловых префиксов, формирующихся при сохранении видео.

Для обеспечения отказоустойчивости используем стандартную master-slave репликацию с 2 репликами master-server.
Master-server будет принимать запросы на запись, реплики - на чтение. При выходе из строя master-server, одна из реплик
возмет на себя запросы на изменение. При выходе из строя всех реплик, запросы будут приходить только на master-server.

### Выбор технологий

Бэкенд будет реализован с использованием языка golang, который довольно легок в освоении и из коробки уже содержит
необходимый функционал для поточной обработки соединений. Для снижения нагрузки на бэкенд, повышения отказоустойчивости и 
разделения логики можно использовать микросервисную архитектуру, например с использованием GRPC.

Фронтенд будет написан на React+Mobx+Typescript и реализовывать функционал SPA.Сборка будет реализовываться с использованием
webpack. В качестве балнсировщика нагрузки будет использоваться nginx, который будет проксировать запросы в зависимости от источника
на нужный бэкенд.
