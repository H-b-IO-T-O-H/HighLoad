# HighLoad

The project was developed as part of the Technopark's high-load systems course.

---

### Тема проекта:

Социальная сеть - TikTok.

### Целевая аудитория сервиса:

- Российская аудитория ~ [23.1 млн](https://www.businessofapps.com/data/tik-tok-statistics/#5)

### MVP проекта:

1. Авторизация, регистрация, профиль пользователя;
2. Просмотр видео;
3. Поиск.

### Расчет нагрузки (Россия):

#### Исходные данные ([Источник](https://news.cpa.ru/tiktok-showed-audience-statistics/)):

- Среднее время, которое проводит пользователь в приложении за день: 45 мин;
- Среднее число заходов в приложение за день: 6-7;
- Максимальная длина ролика: 1 минута;
- Минимальная длина ролика: 15 секунд;
- Максимальный размер видео: 75Mb (android), 250Mb (ios);
- 73% используют Android-устройства, а 27% – посещают сервис с iOS. 
- Число ежедневных просмотров видео: 666 млн;
- Число ежедневных загрузок видео: 666 тыс;
- Активная аудитория России: [18 млн человек](https://news.cpa.ru/tiktok-showed-audience-statistics/)
- Среднее число [хэштегов в видео: 4](https://rusability.ru/articles/Heshtegi-dlya-Tik-Tok-kak-podobrat,-ispolzovat-i-prodvigatsya-bistree-konkurentov/5fd296ad2dda593c3483efc4);
#### Расчеты:

- Средняя длина ролика ~ 30 сек
- Количество пользователей онлайн в среднем составляет 23.1 * 45 / (24 * 60) ~ 722 000 за 45 минут,
- Среднее число просмотренных видео за день: 45 мин / 1.25 мин = 36 видео. Среднее время одного сеанса пользователя: 45 мин
- Средний объем трафика для одного
  пользователя: [16 Mb/min](https://www.quora.com/What-uses-more-data-watching-YouTube-videos-for-an-hour-or-TikTok-videos-for-an-hour)
- Средний объем выгружаемого на сервер видео-контента: 75 * 0.73 + 250 * 0.27 = 122.25 мб
- Скорость выгрузки контента зависит от скорости интернет соединения (~15Mb/sec) и в среднем составляет: 11 сек; 
  
Будем считать, что информация, сопутствующая видео (число лайков, комментарии, подписки, картинки) занимает
15% от общего объема переданного контента, то есть 0.15 * 16 = 2.4 Mb / min
Отнесем эту работу с этой частью контента к бизнес-логике.
Среднее время одного сеанса пользователя: 45 мин / 6 = 6.5 мин. За это время, учитывая среднее время ролика в 37 сек,
можно успеть посмотреть 10 видео. При этом каждое новое видео требует запроса не только к видеофайлу, но и запроса 
бизнес-логики, который позволит получить число лайков, комментариев, подписчиков и прочие вспомогательные данные. 
Так как при загрузке контента сначала появляется информация о видео, убеждаемся, что происходит как минимум два запроса.

Нагрузка для одного пользователя в секунду | Сеть 
--- | ---
Загрузка видео контента | 16 / 60 * 36 / 60 * 0.85 = **1.1** мбит / с 
Выгрузка видео контента | (666 000 * 45 / (24 * 3600)) / (722 000) * 30 * 4 = **0,46** мбит / с 
Бизнес-логика | 2.4 / 60 = **0.32** мбит / с

Нагрузка дневной аудитории | Сеть 
--- | ---
Загрузка видео контента | 1.1 * 722 000  = **0.76** тбит / c
Выгрузка видео контента | 0.46 * 722 000 = **0.32** тбит / c
Бизнес-логика | 0.32 * 722 000  = **0.22** тбит / c 

Результирующие порядки RPS | RPS
--- | ---
Загрузка видео контента | 0.6 / 60 * 722 * 10 ^ 5 ~= **7200**
Выгрузка видео контента | 666 * 10^5 / (24 * 3600) ~= **770**
Бизнес-логика | 2 * 666 * 10^6 / (24 * 3600) ~= **15400**


При это надо учитывать, что число обращений
может увеличиться в [2 раза](https://habr.com/en/company/dcmiran/blog/496542/) при пиковой нагрузке.

### Логическая схема БД:

---
![Иллюстрация к проекту](https://raw.githubusercontent.com/H-b-IO-T-O-H/HighLoad/main/subd_sheme/subd_logic.png)

### Физическая схема БД:

Размер uuid - 16 bytes.

    videos:
      video_id(16) + title(150) + author_name(24) + autor_id(16) + duration(4) + likes_cnt(8) + audio_file_title(50) + path_to_video_file(128) + file_prefix(16) = 412 bytes
      
    Количество загружаемых видео: 20 * 10^6 / month, на первый год потребуется 12 * 20 * 10^6 * 412 ~ 92.1 Gb для хранения в бд 
    и так как средняя длина видео равна 30 секундам, то средний объём одного видео равен 30 * 16.3 / 8 = 61 мб. 
    Тогда на год потребуется 12 * 20 * 10^6 * 61 = 16.3 мбит / с. ~ 13962 Tb в файловом хранилище
    
    users:
      user_id(16) + name(20) + username(24) + email(128) + phone(11) + password(128) + total_likes_cnt(8) + followers_cnt(8) + following_cnt(8) + recommendation_id(16) = 367 bytes
      Количество пользователей в России: 23.1 * 10^6, потребуется 23.1 * 10^6 * 367 ~ 7.9 Gb
    
    followers:
      follower_id(16) + user_id(16) + follower_name(24) = 56 bytes
      Будем считать только Российский сегмент без подписок на иностранных авторов: 
      потребуется 23.1 * 10^6 * 56 ~ 1.2 Gb
    
    hashtags:
      hashtag_id(16) + hashtag(100) + followers_cnt(8) + is_trend(1) ~ 125 bytes
      В среднем для видео генерируется 4 хэштега. Для Российского сегмента потребуется:
      12 * 20 * 4 * 10^6 * 125 ~ 111 Gb

    recommendations:
      Предположим, рекомендации пользователя определяются на основании 10 последних просмотренных видео и 5 наиболее популярных хэштегов.
      recommendation_id(16) + user_id(16) + favourites_videos_id(16 * 10) +  favourites_hashtags_id(16 * 5) + average_video_duration(4) = 356 bytes
      23.1 * 10^6 * 356 ~ 7.66 Gb

|Сущность|Объем памяти на год работы|
| -------------  | :-------------:  |
|Users|7.9 Гб|
|Recommendations|7.66 Гб|
|Videos|92.1 Гб / 13.63 Пб|
|Hashtags|111 Гб|
|Followers|1.2 Гб|

### Выбор СУБД

Данные пользователей, информацию о видео, подписках и рекоммендациях будут храниться в PostgreSQL, как в хорошо
зарекомендовавшей себя реляционной БД, котарая поддерживает все необходимые средства для ораганизации распределенных
систем. Данные о сессии будут храниться в Redis из-за его высокой скорости работы.

### Шардирование и репликация

- Видео будет распределено на нескольких файловых хранилищах (например HDD) на основании файловых префиксов, формирующихся при сохранении видео.

Для обеспечения отказоустойчивости используем стандартную master-slave репликацию с 2 репликами master-server.
Master-server будет принимать запросы на запись, реплики - на чтение. При выходе из строя master-server, одна из реплик
возмет на себя запросы на изменение. При выходе из строя всех реплик, запросы будут приходить только на master-server.

### Выбор технологий

Бэкенд будет реализован с использованием языка golang, который довольно легок в освоении и из коробки уже содержит
необходимый функционал для поточной обработки соединений. Для снижения нагрузки на бэкенд, повышения отказоустойчивости и 
разделения логики можно использовать микросервисную архитектуру, например с использованием GRPC.

Фронтенд будет написан на React+Mobx+Typescript и реализовывать функционал SPA.Сборка будет реализовываться с использованием
webpack. В качестве балнсировщика нагрузки будет использоваться nginx, который будет проксировать запросы в зависимости от источника
на нужный бэкенд.
